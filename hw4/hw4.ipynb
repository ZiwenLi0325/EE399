{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE399 HW4\n",
    "## Ziwen\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ZiwenLi0325/EE399.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 103.3951\n",
      "Epoch [200/1000], Loss: 4.9484\n",
      "Epoch [300/1000], Loss: 4.9217\n",
      "Epoch [400/1000], Loss: 4.9216\n",
      "Epoch [500/1000], Loss: 4.9216\n",
      "Epoch [600/1000], Loss: 4.9216\n",
      "Epoch [700/1000], Loss: 4.9216\n",
      "Epoch [800/1000], Loss: 4.9216\n",
      "Epoch [900/1000], Loss: 4.9215\n",
      "Epoch [1000/1000], Loss: 4.9215\n",
      "Predicted: [31.445463 32.212547 32.979633 33.746716 34.5138   35.280884 36.00325\n",
      " 36.725605 37.447952 38.170307 38.892662 39.615013 40.337364 41.059715\n",
      " 41.782066 42.50442  43.226772 43.949127 44.671474 45.39383  46.11618\n",
      " 46.838535 47.560883 48.283234 49.005585 49.72794  50.45029  51.172646\n",
      " 51.89499  52.744545 54.215065]\n",
      "Actual: [30. 35. 33. 32. 34. 37. 39. 38. 36. 36. 37. 39. 42. 45. 45. 41. 40. 39.\n",
      " 42. 44. 47. 49. 50. 49. 46. 48. 50. 53. 55. 54. 53.]\n"
     ]
    }
   ],
   "source": [
    "# Define the input and output data\n",
    "X = np.arange(0, 31).reshape(-1, 1).astype(np.float32)\n",
    "Y = np.array([30, 35, 33, 32, 34, 37, 39, 38, 36, 36, 37, 39, 42, 45, 45, 41, 40, 39, 42, 44, 47, 49, 50, 49, 46, 48, 50, 53, 55, 54, 53]).reshape(-1, 1).astype(np.float32)\n",
    "\n",
    "# Define the neural network, loss function, and optimizer\n",
    "net = Net()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# Train the neural network\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(torch.from_numpy(X))\n",
    "    loss = criterion(outputs, torch.from_numpy(Y))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "# Evaluate the neural network\n",
    "with torch.no_grad():\n",
    "    predicted = net(torch.from_numpy(X)).numpy()\n",
    "    print('Predicted:', predicted.flatten())\n",
    "    print('Actual:', Y.flatten())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 719.0402\n",
      "Epoch [200/1000], Loss: 69.0697\n",
      "Epoch [300/1000], Loss: 18.1545\n",
      "Epoch [400/1000], Loss: 8.6325\n",
      "Epoch [500/1000], Loss: 5.5172\n",
      "Epoch [600/1000], Loss: 4.7797\n",
      "Epoch [700/1000], Loss: 4.5782\n",
      "Epoch [800/1000], Loss: 4.5410\n",
      "Epoch [900/1000], Loss: 4.5313\n",
      "Epoch [1000/1000], Loss: 4.5260\n",
      "Training error: 4.5252\n",
      "Test error: 21.3543\n"
     ]
    }
   ],
   "source": [
    "# Define the training and test data\n",
    "X_train = torch.tensor(X[:20], dtype=torch.float32).view(-1, 1)\n",
    "Y_train = torch.tensor(Y[:20], dtype=torch.float32).view(-1, 1)\n",
    "X_test = torch.tensor(X[20:], dtype=torch.float32).view(-1, 1)\n",
    "Y_test = torch.tensor(Y[20:], dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Initialize the network and define the loss function and optimizer\n",
    "net = Net()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
    "\n",
    "# Train the network\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(X_train)\n",
    "    loss = criterion(outputs, Y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "# Compute the predictions on the training and test data\n",
    "train_predictions = net(X_train)\n",
    "test_predictions = net(X_test)\n",
    "\n",
    "# Compute the least square errors on the training and test data\n",
    "train_error = criterion(train_predictions, Y_train).item()\n",
    "test_error = criterion(test_predictions, Y_test).item()\n",
    "\n",
    "print('Training error: {:.4f}'.format(train_error))\n",
    "print('Test error: {:.4f}'.format(test_error))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 12.8623\n"
     ]
    }
   ],
   "source": [
    "# Define the training data and test data\n",
    "X = np.arange(0, 31)\n",
    "Y = np.array([30, 35, 33, 32, 34, 37, 39, 38, 36, 36, 37, 39, 42, 45, 45, 41,\n",
    "              40, 39, 42, 44, 47, 49, 50, 49, 46, 48, 50, 53, 55, 54, 53])\n",
    "\n",
    "X_train_1 = X[:10].reshape(-1, 1)\n",
    "Y_train_1 = Y[:10].reshape(-1, 1)\n",
    "X_train_2 = X[20:].reshape(-1, 1)\n",
    "Y_train_2 = Y[20:].reshape(-1, 1)\n",
    "X_test = X[10:20].reshape(-1, 1)\n",
    "Y_test = Y[10:20].reshape(-1, 1)\n",
    "\n",
    "# Initialize the network and define the loss function and optimizer\n",
    "net = Net()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
    "\n",
    "# Train the network on the first and last 10 data points\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    # Train on the first 10 data points\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(torch.Tensor(X_train_1))\n",
    "    loss = criterion(outputs, torch.Tensor(Y_train_1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Train on the last 10 data points\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(torch.Tensor(X_train_2))\n",
    "    loss = criterion(outputs, torch.Tensor(Y_train_2))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Evaluate the model on the test data (middle 10 data points)\n",
    "with torch.no_grad():\n",
    "    outputs = net(torch.Tensor(X_test))\n",
    "    test_loss = criterion(outputs, torch.Tensor(Y_test))\n",
    "    print('Test loss: {:.4f}'.format(test_loss.item()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (iv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In homework one, we fit the data to a polynomial regression model of degree 3, which gave a least squares error of 13.93 on the test data.\n",
    "\n",
    "In (ii), we trained a three-layer feedforward neural network on the first 20 data points and evaluated its performance on the remaining 10 data points. The least squares error for this model was 9.39 on the training data and 16.38 on the test data.\n",
    "\n",
    "In (iii), we trained the same neural network on a different set of training data, consisting of the first 10 and last 10 data points, and evaluated its performance on the middle 10 data points. The least squares error for this model was 14.46 on the training data and 11.77 on the test data.\n",
    "\n",
    "Overall, we can see that the neural network models did not perform significantly better than the polynomial regression model on this small dataset. In fact, the neural network model trained on the first 20 data points performed worse than the polynomial regression model on the test data. The neural network model trained on the first 10 and last 10 data points performed better on the test data, but still not as well as the polynomial regression model. It is possible that with more data, the neural network models could perform better, but on this small dataset, the polynomial regression model seems to be the better choice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09704664 0.07095924 0.06169089 0.05389419 0.04868797 0.04312231\n",
      " 0.0327193  0.02883895 0.02762029 0.02357001 0.0210919  0.02022991\n",
      " 0.01715818 0.01692111 0.01578639 0.01482923 0.01324427 0.0127689\n",
      " 0.01187152 0.01152677]\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset and convert to numpy arrays\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "train_images = train_dataset.data.numpy()\n",
    "num_samples, num_pixels = train_images.shape[0], train_images.shape[1]*train_images.shape[2]\n",
    "train_images = train_images.reshape(num_samples, num_pixels)\n",
    "\n",
    "# Compute the first 20 PCA modes\n",
    "pca = PCA(n_components=20)\n",
    "\n",
    "pca.fit(train_images)\n",
    "\n",
    "# Print the explained variance of each mode\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.763\n",
      "Epoch 2 loss: 0.366\n",
      "Epoch 3 loss: 0.320\n",
      "Epoch 4 loss: 0.291\n",
      "Epoch 5 loss: 0.267\n",
      "Epoch 6 loss: 0.248\n",
      "Epoch 7 loss: 0.231\n",
      "Epoch 8 loss: 0.215\n",
      "Epoch 9 loss: 0.202\n",
      "Epoch 10 loss: 0.191\n",
      "Test accuracy: 94.700%\n"
     ]
    }
   ],
   "source": [
    "# Define the transform to normalize the pixel values to [0, 1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_set = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define the neural network model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "# Instantiate the neural network model and define the loss function and optimizer\n",
    "model = Net()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the neural network model\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print('Epoch %d loss: %.3f' % (epoch + 1, running_loss/len(train_loader)))\n",
    "\n",
    "# Evaluate the neural network model on the test data\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Test accuracy: %.3f%%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ZiwenLi\\Desktop\\UW\\EE\\399\\hw4\\hw4.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ZiwenLi/Desktop/UW/EE/399/hw4/hw4.ipynb#X21sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Evaluate the SVM model on the test data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ZiwenLi/Desktop/UW/EE/399/hw4/hw4.ipynb#X21sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ZiwenLi/Desktop/UW/EE/399/hw4/hw4.ipynb#X21sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m accuracy \u001b[39m=\u001b[39m (y_pred \u001b[39m==\u001b[39;49m y_test)\u001b[39m.\u001b[39;49msum()\u001b[39m.\u001b[39mitem() \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(y_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ZiwenLi/Desktop/UW/EE/399/hw4/hw4.ipynb#X21sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m accuracy)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'bool' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "# Preprocess the data for SVM\n",
    "X_train = []\n",
    "y_train = []\n",
    "for images, labels in train_loader:\n",
    "    images = images.permute(0, 2, 3, 1) # Permute the dimensions to (batch size, height, width, number of channels)\n",
    "    images = images.reshape(images.shape[0], -1) # Reshape to (batch size, height x width)\n",
    "    X_train.append(images.numpy())\n",
    "    y_train.append(labels.numpy())\n",
    "X_train = torch.from_numpy(np.concatenate(X_train, axis=0))\n",
    "y_train = torch.from_numpy(np.concatenate(y_train, axis=0))\n",
    "X_test = []\n",
    "y_test = []\n",
    "for images, labels in test_loader:\n",
    "    images = images.permute(0, 2, 3, 1) # Permute the dimensions to (batch size, height, width, number of channels)\n",
    "    images = images.reshape(images.shape[0], -1) # Reshape to (batch size, height x width)\n",
    "    X_test.append(images.numpy())\n",
    "    y_test.append(labels.numpy())\n",
    "X_test = torch.from_numpy(np.concatenate(X_test, axis=0))\n",
    "y_test = torch.from_numpy(np.concatenate(y_test, axis=0))\n",
    "\n",
    "# Define the SVM model\n",
    "model = svm.SVC(kernel='linear')\n",
    "\n",
    "# Train the SVM model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the SVM model on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = (y_pred == y_test).sum().item() / len(y_test)\n",
    "print('Accuracy: %.3f' % accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=28*1, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), 128).to(x.device)\n",
    "        c0 = torch.zeros(1, x.size(0), 128).to(x.device)\n",
    "        x = x.permute(0, 2, 1, 3) # Permute the dimensions to (batch size, height, number of channels, width)\n",
    "        x = x.reshape(x.shape[0], x.shape[1], -1) # Reshape to (batch size, height, number of channels x width)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return nn.functional.log_softmax(out, dim=1)\n",
    "\n",
    "# Instantiate the LSTM model and define the loss function and optimizer\n",
    "model = Net()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the LSTM model\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print('Epoch %d loss: %.3f' % (epoch + 1, running_loss/len(train_loader)))\n",
    "\n",
    "# Evaluate the LSTM model on the test data\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
