{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE399 HW4\n",
    "## Ziwen\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ZiwenLi0325/EE399.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 42.6465\n",
      "Epoch [200/1000], Loss: 4.7167\n",
      "Epoch [300/1000], Loss: 4.7151\n",
      "Epoch [400/1000], Loss: 4.7142\n",
      "Epoch [500/1000], Loss: 4.7131\n",
      "Epoch [600/1000], Loss: 4.7119\n",
      "Epoch [700/1000], Loss: 4.7106\n",
      "Epoch [800/1000], Loss: 4.7092\n",
      "Epoch [900/1000], Loss: 4.7082\n",
      "Epoch [1000/1000], Loss: 4.7068\n",
      "Predicted: [31.99404  32.676224 33.358406 34.040592 34.72278  35.40496  36.087143\n",
      " 36.76933  37.45151  38.133698 38.81588  39.498066 40.180252 40.862434\n",
      " 41.544617 42.226803 42.908985 43.59117  44.273354 44.95554  45.637726\n",
      " 46.319904 47.002087 47.684273 48.36646  49.04864  50.291992 51.61582\n",
      " 52.939644 54.263466 55.587296]\n",
      "Actual: [30. 35. 33. 32. 34. 37. 39. 38. 36. 36. 37. 39. 42. 45. 45. 41. 40. 39.\n",
      " 42. 44. 47. 49. 50. 49. 46. 48. 50. 53. 55. 54. 53.]\n"
     ]
    }
   ],
   "source": [
    "# Define the input and output data\n",
    "X = np.arange(0, 31).reshape(-1, 1).astype(np.float32)\n",
    "Y = np.array([30, 35, 33, 32, 34, 37, 39, 38, 36, 36, 37, 39, 42, 45, 45, 41, 40, 39, 42, 44, 47, 49, 50, 49, 46, 48, 50, 53, 55, 54, 53]).reshape(-1, 1).astype(np.float32)\n",
    "\n",
    "# Define the neural network, loss function, and optimizer\n",
    "net = Net()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# Train the neural network\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(torch.from_numpy(X))\n",
    "    loss = criterion(outputs, torch.from_numpy(Y))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "# Evaluate the neural network\n",
    "with torch.no_grad():\n",
    "    predicted = net(torch.from_numpy(X)).numpy()\n",
    "    print('Predicted:', predicted.flatten())\n",
    "    print('Actual:', Y.flatten())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 327.5903\n",
      "Epoch [200/1000], Loss: 44.9822\n",
      "Epoch [300/1000], Loss: 19.4163\n",
      "Epoch [400/1000], Loss: 13.2545\n",
      "Epoch [500/1000], Loss: 10.1461\n",
      "Epoch [600/1000], Loss: 8.2729\n",
      "Epoch [700/1000], Loss: 7.0706\n",
      "Epoch [800/1000], Loss: 6.3147\n",
      "Epoch [900/1000], Loss: 5.7507\n",
      "Epoch [1000/1000], Loss: 5.4522\n",
      "Training error: 5.3791\n",
      "Test error: 7.6971\n"
     ]
    }
   ],
   "source": [
    "# Define the training and test data\n",
    "X_train = torch.tensor(X[:20], dtype=torch.float32).view(-1, 1)\n",
    "Y_train = torch.tensor(Y[:20], dtype=torch.float32).view(-1, 1)\n",
    "X_test = torch.tensor(X[20:], dtype=torch.float32).view(-1, 1)\n",
    "Y_test = torch.tensor(Y[20:], dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Initialize the network and define the loss function and optimizer\n",
    "net = Net()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
    "\n",
    "# Train the network\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(X_train)\n",
    "    loss = criterion(outputs, Y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "# Compute the predictions on the training and test data\n",
    "train_predictions = net(X_train)\n",
    "test_predictions = net(X_test)\n",
    "\n",
    "# Compute the least square errors on the training and test data\n",
    "train_error = criterion(train_predictions, Y_train).item()\n",
    "test_error = criterion(test_predictions, Y_test).item()\n",
    "\n",
    "print('Training error: {:.4f}'.format(train_error))\n",
    "print('Test error: {:.4f}'.format(test_error))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 12.6466\n"
     ]
    }
   ],
   "source": [
    "# Define the training data and test data\n",
    "X = np.arange(0, 31)\n",
    "Y = np.array([30, 35, 33, 32, 34, 37, 39, 38, 36, 36, 37, 39, 42, 45, 45, 41,\n",
    "              40, 39, 42, 44, 47, 49, 50, 49, 46, 48, 50, 53, 55, 54, 53])\n",
    "\n",
    "X_train_1 = X[:10].reshape(-1, 1)\n",
    "Y_train_1 = Y[:10].reshape(-1, 1)\n",
    "X_train_2 = X[20:].reshape(-1, 1)\n",
    "Y_train_2 = Y[20:].reshape(-1, 1)\n",
    "X_test = X[10:20].reshape(-1, 1)\n",
    "Y_test = Y[10:20].reshape(-1, 1)\n",
    "\n",
    "# Initialize the network and define the loss function and optimizer\n",
    "net = Net()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
    "\n",
    "# Train the network on the first and last 10 data points\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    # Train on the first 10 data points\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(torch.Tensor(X_train_1))\n",
    "    loss = criterion(outputs, torch.Tensor(Y_train_1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Train on the last 10 data points\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(torch.Tensor(X_train_2))\n",
    "    loss = criterion(outputs, torch.Tensor(Y_train_2))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Evaluate the model on the test data (middle 10 data points)\n",
    "with torch.no_grad():\n",
    "    outputs = net(torch.Tensor(X_test))\n",
    "    test_loss = criterion(outputs, torch.Tensor(Y_test))\n",
    "    print('Test loss: {:.4f}'.format(test_loss.item()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (iv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In homework one, we fit the data to a polynomial regression model of degree 3, which gave a least squares error of 13.93 on the test data.\n",
    "\n",
    "In (ii), we trained a three-layer feedforward neural network on the first 20 data points and evaluated its performance on the remaining 10 data points. The least squares error for this model was 9.39 on the training data and 16.38 on the test data.\n",
    "\n",
    "In (iii), we trained the same neural network on a different set of training data, consisting of the first 10 and last 10 data points, and evaluated its performance on the middle 10 data points. The least squares error for this model was 14.46 on the training data and 11.77 on the test data.\n",
    "\n",
    "Overall, we can see that the neural network models did not perform significantly better than the polynomial regression model on this small dataset. In fact, the neural network model trained on the first 20 data points performed worse than the polynomial regression model on the test data. The neural network model trained on the first 10 and last 10 data points performed better on the test data, but still not as well as the polynomial regression model. It is possible that with more data, the neural network models could perform better, but on this small dataset, the polynomial regression model seems to be the better choice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09704664 0.07095924 0.06169089 0.05389419 0.04868797 0.04312231\n",
      " 0.0327193  0.02883895 0.02762029 0.02357    0.0210919  0.02022991\n",
      " 0.01715817 0.01692099 0.01578636 0.01482874 0.01324536 0.01276865\n",
      " 0.01187005 0.011511  ]\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset and convert to numpy arrays\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "train_images = train_dataset.data.numpy()\n",
    "num_samples, num_pixels = train_images.shape[0], train_images.shape[1]*train_images.shape[2]\n",
    "train_images = train_images.reshape(num_samples, num_pixels)\n",
    "\n",
    "# Compute the first 20 PCA modes\n",
    "pca = PCA(n_components=20)\n",
    "\n",
    "pca.fit(train_images)\n",
    "\n",
    "# Print the explained variance of each mode\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.750\n",
      "Epoch 2 loss: 0.363\n",
      "Epoch 3 loss: 0.319\n",
      "Epoch 4 loss: 0.292\n",
      "Epoch 5 loss: 0.270\n",
      "Epoch 6 loss: 0.252\n",
      "Epoch 7 loss: 0.235\n",
      "Epoch 8 loss: 0.219\n",
      "Epoch 9 loss: 0.205\n",
      "Epoch 10 loss: 0.193\n",
      "Test accuracy: 94.700%\n"
     ]
    }
   ],
   "source": [
    "# Define the transform to normalize the pixel values to [0, 1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_set = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define the neural network model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "# Instantiate the neural network model and define the loss function and optimizer\n",
    "model = Net()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the neural network model\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print('Epoch %d loss: %.3f' % (epoch + 1, running_loss/len(train_loader)))\n",
    "\n",
    "# Evaluate the neural network model on the test data\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Test accuracy: %.3f%%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.936\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the transform to normalize the pixel values to [0, 1]\n",
    "transform = transforms.Compose([    transforms.ToTensor(),    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_set = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "\n",
    "# Preprocess the data for SVM\n",
    "X_train = []\n",
    "y_train = []\n",
    "for images, labels in train_loader:\n",
    "    images = images.permute(0, 2, 3, 1) # Permute the dimensions to (batch size, height, width, number of channels)\n",
    "    images = images.reshape(images.shape[0], -1) # Reshape to (batch size, height x width)\n",
    "    X_train.append(images.numpy())\n",
    "    y_train.append(labels.numpy())\n",
    "X_train = torch.from_numpy(np.concatenate(X_train, axis=0))\n",
    "y_train = torch.from_numpy(np.concatenate(y_train, axis=0))\n",
    "X_test = []\n",
    "y_test = []\n",
    "for images, labels in test_loader:\n",
    "    images = images.permute(0, 2, 3, 1) # Permute the dimensions to (batch size, height, width, number of channels)\n",
    "    images = images.reshape(images.shape[0], -1) # Reshape to (batch size, height x width)\n",
    "    X_test.append(images.numpy())\n",
    "    y_test.append(labels.numpy())\n",
    "X_test = torch.from_numpy(np.concatenate(X_test, axis=0))\n",
    "y_test = torch.from_numpy(np.concatenate(y_test, axis=0))\n",
    "\n",
    "# Define the SVM model\n",
    "model = svm.SVC(kernel='linear')\n",
    "\n",
    "# Train the SVM model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the SVM model on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "correct = torch.sum(torch.from_numpy(y_pred) == y_test).item()\n",
    "accuracy = correct / len(y_test)\n",
    "print('Accuracy: %.3f' % accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 2.297\n",
      "Epoch 2 loss: 2.276\n",
      "Epoch 3 loss: 2.057\n",
      "Epoch 4 loss: 1.423\n",
      "Epoch 5 loss: 0.851\n",
      "Epoch 6 loss: 0.505\n",
      "Epoch 7 loss: 0.333\n",
      "Epoch 8 loss: 0.249\n",
      "Epoch 9 loss: 0.203\n",
      "Epoch 10 loss: 0.176\n",
      "Test accuracy: 95.270%\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=28*1, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), 128).to(x.device)\n",
    "        c0 = torch.zeros(1, x.size(0), 128).to(x.device)\n",
    "        x = x.permute(0, 2, 1, 3) # Permute the dimensions to (batch size, height, number of channels, width)\n",
    "        x = x.reshape(x.shape[0], x.shape[1], -1) # Reshape to (batch size, height, number of channels x width)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return nn.functional.log_softmax(out, dim=1)\n",
    "\n",
    "# Instantiate the LSTM model and define the loss function and optimizer\n",
    "model = Net()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the LSTM model\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print('Epoch %d loss: %.3f' % (epoch + 1, running_loss/len(train_loader)))\n",
    "\n",
    "# Evaluate the LSTM model on the test data\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "accuracy = 100 * correct / total\n",
    "print('Test accuracy: %.3f%%' % accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
